# routers\input_router.py

from pathlib import Path
import os
import torch
import requests
from pydantic import BaseModel
from transformers import ElectraForSequenceClassification, ElectraTokenizer
from fastapi import APIRouter

router = APIRouter()

# ë¼ë²¨ ë§¤í•‘
id2label = {0: "ë‚ ì”¨", 1: "ë‰´ìŠ¤", 2: "ì´ì•¼ê¸°"}

# ëª¨ë¸ ê²½ë¡œ
project_root = Path(__file__).resolve().parents[1]
model_dir = project_root / "best_model"
model_file = model_dir / "model.safetensors"

# Google Drive ë‹¤ìš´ë¡œë“œ URL
GDRIVE_MODEL_URL = "https://drive.google.com/uc?export=download&id=1h-x9OPeJA3Oexg_KIsNhn12NA-Cu0KQL"

# ëª¨ë¸ì´ ì—†ì„ ë•Œë§Œ ë‹¤ìš´ë¡œë“œ
def download_model_if_needed():
    if model_file.exists():
        print("âœ… ëª¨ë¸ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ìƒëµ.")
        return
    print("ğŸ“¥ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...")
    os.makedirs(model_dir, exist_ok=True)
    response = requests.get(GDRIVE_MODEL_URL, stream=True)
    if response.status_code == 200:
        with open(model_file, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        print("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ.")
    else:
        raise RuntimeError(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. ì‘ë‹µ ì½”ë“œ: {response.status_code}")

# ìµœì´ˆ ì‹¤í–‰ ì‹œ ëª¨ë¸ ì²´í¬
download_model_if_needed()

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”©
tokenizer = ElectraTokenizer.from_pretrained(model_dir)
model = ElectraForSequenceClassification.from_pretrained(model_dir)
model.eval()

# ì…ë ¥ ë°ì´í„° êµ¬ì¡°
class TextInput(BaseModel):
    text: str

# API ì—”ë“œí¬ì¸íŠ¸
@router.post("/classify")
def classify_text(input_data: TextInput):
    text = input_data.text.strip()
    if not text:
        return {"error": "ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."}

    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1).squeeze()
        pred_id = torch.argmax(probs).item()
        confidence = probs[pred_id].item()

    return {
        "label": id2label[pred_id],
        "confidence": round(confidence, 4)
    }
