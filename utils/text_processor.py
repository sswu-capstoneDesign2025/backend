import openai
import os
from dotenv import load_dotenv
from openai import OpenAI, AsyncOpenAI
import re
import pickle

from utils.keyword_extractor import (
    extract_keyword_from_text,
    extract_passages_by_keywords
)

CACHE_PATH = "summary_cache.pkl"
SUMMARY_CACHE = {}
# ì„œë²„ ì‹œì‘ ì‹œ ìºì‹œ ë¡œë“œ
if os.path.exists(CACHE_PATH):
    try:
        with open(CACHE_PATH, "rb") as f:
            SUMMARY_CACHE = pickle.load(f)
        print(f"ğŸ“‚ ìºì‹œ ë¡œë“œ ì™„ë£Œ: {len(SUMMARY_CACHE)}ê°œ")
    except Exception as e:
        print(f"â— ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")


load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
client = AsyncOpenAI()

async def long_article_summary(text: str) -> str:
    """
    1ì°¨ ìš”ì•½: GPT-3.5-turbo ë¡œ ê¸´ ë³¸ë¬¸ì„ ì••ì¶•í•´ì„œ 500~700ì ì´ë‚´ë¡œ ì¤„ì—¬ì¤Œ
    """
    prompt = f"""
    ë‹¤ìŒ ë‰´ìŠ¤ ë³¸ë¬¸ì„ 500ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì¤˜.
    ë‰´ìŠ¤ ê¸°ì‚¬ì²˜ëŸ¼ ì“°ë˜, êµ¬ì–´ì²´ëŠ” ì“°ì§€ ë§ê³  í•µì‹¬ë§Œ ë‹´ì•„ì¤˜.

    [ë‰´ìŠ¤ ë³¸ë¬¸]
    {text}

    [ì¶œë ¥ í˜•ì‹]
    - ìš”ì•½:
    """
    resp = await client.chat.completions.create(
        model="gpt-3.5-turbo-0125",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ë‰´ìŠ¤ ìš”ì•½ ì „ë¬¸ê°€ì•¼."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        max_tokens=800
    )
    out = resp.choices[0].message.content
    m = re.search(r"ìš”ì•½:\s*(.+)", out, re.DOTALL)
    return m.group(1).strip() if m else out.strip()


async def simplify_for_borderline(text: str) -> str:
    """
    2ì°¨ ë‹¤ë“¬ê¸°: 
    - ê²½ê³„ì„  ì§€ëŠ¥ ìˆ˜ì¤€ ì‚¬ìš©ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡
    - ë¬¸ì¥ì€ ì§§ê³  ê°„ë‹¨í•˜ê²Œ
    - ì–´ë ¤ìš´ ë‹¨ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ ë°”ê¿”ì¤Œ
    """
    prompt = f"""
    ì•„ë˜ëŠ” ì´ë¯¸ ìš”ì•½ëœ ë‰´ìŠ¤ì…ë‹ˆë‹¤.
    ê²½ê³„ì„  ì§€ëŠ¥í˜• ì¥ì• ì¸ ìˆ˜ì¤€ì˜ ì‚¬ìš©ìë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆê²Œ í•˜ë‚˜ì˜ ë‰´ìŠ¤ë¡œ ì¬ì‘ì„±í•´ì£¼ì„¸ìš”.
    - í•œ ë¬¸ì¥ì— í•˜ë‚˜ì˜ ì •ë³´ë§Œ ë‹´ì•„ì£¼ì„¸ìš”.
    - ë¬¸ì¥ì€ ìµœëŒ€ 2~3ì¤„ë¡œ ì§§ê²Œ.
    - ì–´ë ¤ìš´ ë‹¨ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.
    - í•„ìš”í•˜ë‹¤ë©´ ì–´ë ¤ìš´ ë§ ì•ì— ì¶”ê°€ ì„¤ëª…ì„ ë„£ì–´ì£¼ì„¸ìš”.(ex. ë°°í„°ë¦¬ì˜ í•œ ì¢…ë¥˜ì¸ ë‚©ì¶•ì „ì§€)
    - ì¹œê·¼í•˜ê²Œ ë§í•˜ëŠ” ë§íˆ¬ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.
    
    [ìš”ì•½ëœ ë‰´ìŠ¤]
    {text}

    [ì¶œë ¥ í˜•ì‹]
    - ê°„ë‹¨í•œ ìš”ì•½:
    """
    resp = await client.chat.completions.create(
        model="gpt-3.5-turbo-0125",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì–´ë¦°ì´ìš© ë‰´ìŠ¤ í¸ì§‘ìì•¼."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
        max_tokens=1000
    )
    out = resp.choices[0].message.content
    m = re.search(r"ê°„ë‹¨í•œ ìš”ì•½:\s*(.+)", out, re.DOTALL)
    return m.group(1).strip() if m else out.strip()


async def summarize_article_pipeline(url: str, text: str, user_query: str, window: int = 1) -> str:
    """
    1) user_queryì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
    2) ê¸°ì‚¬ ë³¸ë¬¸ì—ì„œ í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ì¥ë§Œ í•„í„°ë§
    3) GPT-3.5ë¡œ ì••ì¶• ìš”ì•½ â†’ ì–´ë¦°ì´ìš©ìœ¼ë¡œ ì‰¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
    + ìºì‹œ ì ìš©
    """
    cache_key = f"{url}|{user_query}"
    if cache_key in SUMMARY_CACHE:
        return SUMMARY_CACHE[cache_key]

    keywords = extract_keyword_from_text(user_query)
    filtered = extract_passages_by_keywords(text, keywords, window=window)

    short = await long_article_summary(filtered)            
    simplified = await simplify_for_borderline(short)      

    SUMMARY_CACHE[cache_key] = simplified
    with open(CACHE_PATH, "wb") as f:
        pickle.dump(SUMMARY_CACHE, f)

    return simplified


async def combine_summaries_into_story(summaries: list[str]) -> str:
    """
    ì—¬ëŸ¬ ìš”ì•½ì„ í•˜ë‚˜ë¡œ ë¬¶ì€ ë’¤, 
    ê²½ê³„ì„  ì§€ëŠ¥ ìˆ˜ì¤€ì˜ ì‚¬ìš©ìë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì‰½ê³  ëª…í™•í•˜ê²Œ ì •ë¦¬
    """
    combined = "\n\n".join(summaries)
    prompt = f"""
    ì•„ë˜ëŠ” ì—¬ëŸ¬ ë‰´ìŠ¤ ìš”ì•½ì…ë‹ˆë‹¤.
    ì´ë“¤ì„ ì¤‘ë³µ ì—†ì´ í•˜ë‚˜ì˜ ì‰½ê³  ëª…í™•í•œ ì´ì•¼ê¸°ë¡œ ì´ì–´ì£¼ì„¸ìš”.
    - ë¬¸ì¥ì€ ì§§ê²Œ, í•œ ë¬¸ì¥ë‹¹ í•˜ë‚˜ì˜ ì •ë³´.
    - ì–´ë ¤ìš´ ìš©ì–´ ëŒ€ì‹  ì‰¬ìš´ ë§ ì‚¬ìš©.
    - í•„ìš”í•˜ë©´ ê´„í˜¸ ì•ˆì— ê°„ë‹¨í•œ ì¶”ê°€ ì„¤ëª… í¬í•¨.
    - ë§ˆì§€ë§‰ì— 'ì´ìƒì´ ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ì…ë‹ˆë‹¤.'ë¡œ ë§ˆë¬´ë¦¬.

    [ìš”ì•½ ëª©ë¡]
    {combined}

    [ì¶œë ¥ í˜•ì‹]
    - ì‰¬ìš´ ë‰´ìŠ¤:
    """
    resp = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì–´ë¦°ì´ìš© ë‰´ìŠ¤ í¸ì§‘ìì•¼."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
        max_tokens=1200
    )
    out = resp.choices[0].message.content
    m = re.search(r"ì‰¬ìš´ ë‰´ìŠ¤:\s*(.+)", out, re.DOTALL)
    return m.group(1).strip() if m else out.strip()