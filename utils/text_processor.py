# OpenAIë¡œ í…ìŠ¤íŠ¸ ì •ì œ, ìš”ì•½ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ ëª¨ë“ˆ

import openai
import os
from dotenv import load_dotenv
from openai import OpenAI
import re

load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI()

def process_text_with_gpt(text: str):
    """
    ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼
    - í‘œì¤€ì–´ë¡œ ì •ì œ
    - ë¹„ì†ì–´ ì œê±°
    - í•µì‹¬ ìš”ì•½
    í•˜ëŠ” í•¨ìˆ˜ (Ultimate Robust Version)
    """
    prompt = f"""
    ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í‘œì¤€ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°”ê¾¸ê³ , ìš•ì„¤ ë° ë¶€ì ì ˆí•œ í‘œí˜„ì€ ëª¨ë‘ ì œê±°í•œ í›„, í•µì‹¬ ë‚´ìš©ë§Œ ê°„ë‹¨íˆ ìš”ì•½í•´ì¤˜.

    [í…ìŠ¤íŠ¸]
    {text}

    [ì¶œë ¥í˜•ì‹]
    - í‘œì¤€ì–´ ë¬¸ì¥:
    - ë¹„ì†ì–´ ì œê±°í•œ ë¬¸ì¥:
    - ìš”ì•½ ë¬¸ì¥:
    """

    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì‚¬íˆ¬ë¦¬ì™€ ë¹„ì†ì–´ë¥¼ ì •ì œí•˜ê³  í•µì‹¬ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )

    output = response.choices[0].message.content
    print("ğŸ›° GPT ì‘ë‹µ í™•ì¸:", output)

    # ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ìœ¼ë¡œ íŒŒì‹±
    standardized_text = re.search(r"- í‘œì¤€ì–´ ë¬¸ì¥:\s*(.+?)(?:- ë¹„ì†ì–´ ì œê±°í•œ ë¬¸ì¥:|$)", output, re.DOTALL)
    cleaned_text = re.search(r"- ë¹„ì†ì–´ ì œê±°í•œ ë¬¸ì¥:\s*(.+?)(?:- ìš”ì•½ ë¬¸ì¥:|$)", output, re.DOTALL)
    summary_text = re.search(r"- ìš”ì•½ ë¬¸ì¥:\s*(.+)", output, re.DOTALL)

    standardized = standardized_text.group(1).strip() if standardized_text else ""
    cleaned = cleaned_text.group(1).strip() if cleaned_text else ""
    summary = summary_text.group(1).strip() if summary_text else ""

    return standardized, cleaned, summary
